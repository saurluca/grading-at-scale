# Dispatcher controls
dispatcher:
  num_runs: 1
  # seeds: [42,43,44]  # optional list; if not provided, random seeds will be used
  # seeds: [42]

  models:
    - Qwen/Qwen3-0.6B
    # - meta-llama/Llama-3.2-1B-Instruct
    # - openai-community/gpt2-large
    # - google/flan-t5-large

# Dataset
dataset:
  dataset_name: SciEntsBank_3way
  test_set_name: SciEntsBank_3way
  # test_set_name: gras

  train_file: train.csv
  val_file: test_uq.csv
  test_file: test_ud.csv

# Output
output:
  dir: ${paths.output_dir}/peft_output
  save_model_locally: false
  push_to_hub: false
  save_strategy: steps

# LoRA configuration
lora:
  r: 8
  alpha: 16
  dropout: 0.2
  target_modules: "all-linear"

# Model-specific training hyperparameters
# Maps model names to their specific batch_size and learning_rate
model_specific_params:
  meta-llama/Llama-3.2-1B-Instruct:
    batch_size:
      train: 16
    learning_rate: 0.0002
  Qwen/Qwen3-0.6B:
    batch_size:
      train: 16
    learning_rate: 0.0005
  openai-community/gpt2-large:
    batch_size:
      train: 8
    learning_rate: 0.0005
  google/flan-t5-large:
    batch_size:
      train: 8
    learning_rate: 0.0005

# Training hyperparameters (defaults, overridden by model_specific_params if available)
training:
  num_epochs: 4 # 4
  batch_size:
    train: 16 # 16
    eval: 128 # 16
  gradient_accumulation_steps: 1
  learning_rate: 0.0005 # 0.0002
  weight_decay: 0.01 # 0.01
  eval_strategy: steps # epoch | steps
  eval_steps: 100 # Evaluation frequency in steps (only used when eval_strategy is overridden to steps)
  early_stopping_patience: 3 # Number of evaluations to wait before early stopping
  logging_steps: 20 # 20
  use_bf16: true # when running on CPU set to false

# Tokenization settings
tokenization:
  include_reference_answer: true # true

# MLflow tracking
mlflow:
  experiment_name: lora_training_comparison_results_final_1
