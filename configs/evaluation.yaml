# Configuration for model evaluation
# Used by: src/evaluation/evaluate_*.py
# Note: This config is merged with base.yaml in the Python code

# Evaluation type
eval_type: api # api | local_classifier

# API-based evaluation (DSPy graders)
api_eval:
  model: gpt-4o-mini
  temperature: 0.6
  cache: true
  max_tokens: 512

  mode: per_question # single | per_question | all
  chain_of_thought: false

  # What to pass to grader
  pass_reference: false
  pass_reference_answer: true

  # Data source
  data:
    infer_path: true # Auto-infer from generation config
    manual_path: null # Or specify directly
    # If infer_path=true, uses generation config to build filename
    # Format: student_answers_c{num_correct}_p{num_partial}_i{num_incorrect}_{model}_{mode}.csv
    num_correct_answers: 1
    num_partial_answers: 1
    num_incorrect_answers: 1
    generation_model: gpt-4o-mini
    generation_mode: per_question

# Local classifier evaluation (fine-tuned model on SciEntsBank)
classifier_eval:
  base_model: meta-llama/Llama-3.2-1B-Instruct
  lora_adapter_dir: ${paths.output_dir}/peft_output/adapter-meta-llama/Llama-3.2-1B-Instruct

  dataset:
    dir: data/SciEntsBank_3way
    split: test_ua

  batch_size: 16
  output_dir: ${paths.output_dir}/scientsbank_eval

# Output settings
output:
  dir: ${paths.synth_dir}
  save_predictions: true
  save_confusion_matrix: true
  save_classification_report: true
