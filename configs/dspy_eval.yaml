# Configuration for DSPy-based API model evaluation
# Used by: src/evaluation/evaluate.py
# Note: This config is merged with base.yaml in the Python code

model:
  # Single model to evaluate
  model: gpt-4o
  # mode: single | per_question
  mode: per_question
  cache: true
  max_tokens: 4096

  with_prompt: false
  pass_reference_answer: true


dataset:
  csv_test: data/gras/test.csv  # Always use test.csv
  # csv_test: data/SciEntsBank_3way/test_ud.csv


evaluation:
  num_threads: 16  # For DSPy batched processing


output:
  dir: ${paths.output_dir}/dspy_eval
