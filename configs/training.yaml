# Dispatcher controls
dispatcher:
  num_runs: 5
  # seeds: [42,43,44]  # optional list; if not provided, random seeds will be used
  # seeds: [42]
  models: 
    - meta-llama/Llama-3.2-1B-Instruct
    - openai-community/gpt2-large
    - google/flan-t5-large
    - Qwen/Qwen3-0.6B

# Dataset
dataset:
  # dataset_name: SciEntsBank_3way # gras
  dataset_name: gras
  
  train_file: train.csv
  val_file: val.csv
  test_file: test.csv

# Output
output:
  dir: ${paths.output_dir}/peft_output
  save_model_locally: false
  push_to_hub: false
  save_strategy: steps

# LoRA configuration
lora:
  r: 8
  alpha: 16
  dropout: 0.1
  target_modules: "all-linear"

# Training hyperparameters
training:
  num_epochs: 4 # 4
  batch_size: 
    train: 8 # 16
    eval: 128 # 16
  gradient_accumulation_steps: 1  # batch_size * gradient_accumulation_steps = 8
  learning_rate: 0.001 # 0.001
  weight_decay: 0.01 # 0.01
  eval_strategy: steps # epoch | steps
  eval_steps: 100  # Evaluation frequency in steps (only used when eval_strategy is overridden to steps)
  early_stopping_patience: 3  # Number of evaluations to wait before early stopping
  logging_steps: 20 # 20

# Tokenization settings
tokenization:
  include_reference_answer: true # true

# MLflow tracking
mlflow:
  experiment_name: lora_training_comparison_results_final
