model:
  # List of models to evaluate (from training.yaml dispatcher.models)
  models: [
    # meta-llama/Llama-3.2-1B-Instruct,
    # openai-community/gpt2-large,
    # google/flan-t5-base,
    # Qwen/Qwen3-0.6B,
    # gpt-4o-mini,
    gpt-4o,
  ]
  cache: true
  # temperature: 0.6
  max_tokens: 4096

  with_prompt: false
  pass_reference_answer: true


dataset:
  # csv_test: data/gras/test.csv  # Always use test.csv
  csv_test: data/SciEntsBank_3way/test_ud.csv


evaluation:
  num_threads: 16  # For DSPy batched processing


output:
  dir: ${paths.output_dir}/baseline

# SELECT *
# FROM train
# WHERE data_source = 'SAF'
# LIMIT 100;

# SELECT 
#     data_source,
#     COUNT(DISTINCT grade) AS num_unique_grades
# FROM 
#     train
# GROUP BY 
#     data_source
# LIMIT 100;