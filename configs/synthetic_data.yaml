# models: apertus-8b, apertus-70b, gpt-4o-mini, gpt-4o, llama3.2:3b, deepseek-r1, llama3.1:8b
model_name: gpt-4o
teacher_model_name: gpt-4o-mini

# Raw input folders (JSON)
raw_tasks_dir: data/raw/tasks
raw_chunks_dir: data/raw/chunks

# Synth output (CSV)
output_dir: data/synth
# tasks_filename: tasks_unified.csv
tasks_filename: all_tasks.csv
infer_data_path: false
data_path: data/SciEntsBank_3way/test_ua.csv

num_correct_answers: 3
num_partial_answers: 3
num_incorrect_answers: 3

lm_temp_eval: 0.6
lm_temp_generation: 1.0
lm_cache: true

# Evaluation batching mode: single | per_question | all
eval_mode: per_question
create_mode: per_question

# Control which fields are passed to models
# Evaluation flags
chain_of_thought: false
eval_pass_reference: false # pass chunk_text as `reference`
eval_pass_reference_answer: true # pass ground-truth as `reference_answer`

# Creation flags (per generator type)
generation:
  chain_of_thought: false

create_pass_reference_for_correct: false
create_pass_reference_answer_for_correct: true
create_pass_reference_for_partial: false
create_pass_reference_answer_for_partial: true
create_pass_reference_for_incorrect: false
create_pass_reference_answer_for_incorrect: false
# total possible combinations:
#20 (questions) * 3 (answers) * 3 (generation) * 3 (eval) * 4 (possible infor gen) * 4 (eval info) = 20 * 3 * 3 * 3 * 4 * 4 = 8640

# Configuration for evaluating a fine-tuned classifier (HF/LoRA) on SciEntsBank
scientsbank:
  dataset_dir: data/SciEntsBank_3way

classifier_eval:
  base_model_name: meta-llama/Llama-3.2-1B-Instruct
  # Path to a trained LoRA adapter directory (as saved by optimisation/lora_base.py)
  # Example: data/peft_output/adapter-meta-llama/Llama-3.2-1B-Instruct
  lora_adapter_dir: data/peft_output/adapter-meta-llama/Llama-3.2-1B-Instruct
  # Optional tokenizer directory to load (if saved separately); if null, uses base model tokenizer
  hf_cache_dir: .hf_cache
  output_dir: data/scientsbank_eval
  batch_size: 16
  eval_split: test_ua
